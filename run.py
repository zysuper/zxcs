import requests
import time
import os
from bs4 import BeautifulSoup
from os import rename
import filetype
import patoolib
import re
import fileinput
import sys
import argparse

download_url = "http://www.zxcs.me/download.php?id="
book_url = "http://www.zxcs.me/post/"

title_string = ""
author_string = ""

no_cover = False

def downloader(url, path):
    start = time.time()
    size = 0
    response = requests.get(url, stream=True)
    chunk_size = 1024
    content_size = int(response.headers['content-length'])
    if response.status_code == 200:
        print('[æ–‡ä»¶åç§°]:%s' % path)
        print('[æ–‡ä»¶å¤§å°]:%0.2f MB' % (content_size / chunk_size / 1024))
        with open(path, 'wb') as file:
            for data in response.iter_content(chunk_size=chunk_size):
                file.write(data)
                size += len(data)
                print('\r'+'[ä¸‹è½½è¿›åº¦]:%s%.2f%%' % ('>'*int(size*50 /
                                                        content_size), float(size / content_size * 100)), end='')
    end = time.time()
    print('\n' + "[ä¸‹è½½çŠ¶æ€]:%sä¸‹è½½å®Œæˆï¼ç”¨æ—¶%.2fç§’" % (path, (end-start)))
    print('------------------------------')


def rename_file(path):
    file_type = filetype.guess(path)
    rename(path, path + '.' + file_type.extension)


def get_one_page(url):
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3325.162 Safari/537.36'
        }
        response = requests.get(url, headers=headers)
        if response.status_code == 200:
            return response.text
        return None
    except RequestException:
        return None


result = input("è¯·è¾“å…¥ä¹¦ç±ç¼–å·: ")

pic_url = (book_url+result)
dl_url = (download_url+result)



def get_file_name(dl_url):
    global title_string
    global author_string
    html = get_one_page(dl_url)
    soup = BeautifulSoup(html, 'lxml')
    path = soup.h2.string
    title_string = re.search(r'(?<=ã€Š)[^ã€‹]+',path)[0]
    author_string = re.search(r'(?<=ä½œè€…ï¼š).*',path)[0]
    return path

filename = (get_file_name(dl_url))

def download_book(dl_url):
    global filename
    html = get_one_page(dl_url)
    soup = BeautifulSoup(html, 'lxml')
    path = filename + '.rar'
    url = soup.find("a", string="çº¿è·¯ä¸€").get("href")
    downloader(url=url, path=path)


def download_pic(pic_url):
    global filename
    html = get_one_page(pic_url)
    soup = BeautifulSoup(html, 'lxml')
    path = filename + '.jpg'
    title = soup.find('title').string.split(" - ")[0]
    print(title)
    try:
        url = soup.find("img", title="ç‚¹å‡»æŸ¥çœ‹åŸå›¾").get("src")
    except:
        url = soup.find("img", alt=title).get("src")
    downloader(url=url, path=path)

def createConvert(title):
    title_with_sp = " ".join(list(title)) 
    font_width = len(title_with_sp) * 63
    x = 280 - (font_width / 2)
    y = 348 
    cmd = """convert -font "éœé¶©æ–‡æ¥·ç­‰å¯¬-TC-Light" -pointsize 70 -draw "text %d,%d '%s'" cover.jpg output.jpg""" % (x, y, title_with_sp)
    print(">> %s\n" % cmd)
    os.system(cmd)


print("å¼€å§‹ä¸‹è½½å°é¢å›¾ç‰‡.....")
try:
    download_pic(pic_url)
except:
    print("!! ä¸‹è½½å°é¢å¤±è´¥...")
    no_cover = True
    print("è‡ªå·±åˆæˆå°é¢...")
    createConvert(title_string)

print("å¼€å§‹ä¸‹è½½ä¹¦ç±å‹ç¼©æ–‡ä»¶.....")
download_book(dl_url)

rarname = filename + ".rar"
jpgname = "output.jpg" if no_cover else filename + ".jpg"
txtname = filename + ".txt"
epubname = title_string + "-" + author_string + ".epub"
print("æ­£åœ¨è§£å‹ç¼©æ–‡ä»¶åˆ°å½“å‰ç›®å½•......")
patoolib.extract_archive(rarname, outdir="./")

print("å¼€å§‹æ–‡ä»¶è½¬ç .......")
f = open(txtname, 'r', encoding="gb18030")
content = f.read()
f.close()
f = open(txtname, 'w', encoding="utf-8")
f.write(content)
f.close()


f = open(txtname,'r', encoding="utf-8")
content = f.read()
f.close()


lines = content.split("\n") 
new_content = []
new_content.append("% "+ title_string)
new_content.append("% "+ author_string)
for line in lines:
    if line == "æ›´å¤šç²¾æ ¡å°è¯´å°½åœ¨çŸ¥è½©è—ä¹¦ä¸‹è½½ï¼šhttp://www.zxcs.me/" or line == "==========================================================" or line == title_string or line == title_string + " ä½œè€…ï¼š" + author_string or line == "ä½œè€…ï¼š" + author_string:
        continue
    
    if line == "å†…å®¹ç®€ä»‹ï¼š":
        new_content.append("# " + line + "\n")
        continue
    if re.match(r'^\s*([ç¬¬åº][0123456789ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åé›¶ã€‡ç™¾åƒä¸¤]*[ç« å›éƒ¨èŠ‚é›†å·]|å·[0123456789ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åé›¶ã€‡ç™¾åƒä¸¤]*).*',line):
        new_content.append("# " + line + "\n")
        continue
    line = line.replace("ã€€ã€€","")
    new_content.append(line + "\n")
new_content = "\n".join(new_content)

f = open(txtname,'w',encoding="utf=8")
f.write(new_content)
f.close
    

print("å¼€å§‹è½¬æ¢EPUBæ–‡ä»¶........")
os.system('pandoc "%s" -o "%s" -t epub3 --css=epub.css --epub-cover-image="%s"' % (txtname, epubname, jpgname))

print("å¼€å§‹è½¬æ¢KEPUBæ–‡ä»¶.........")
os.system('kepubify -i "%s"' % (epubname))

print("åˆ é™¤æ®‹ç•™æ–‡ä»¶......")
os.system("rm '%s'" % (txtname))
os.system("rm '%s'" % (jpgname))
os.system("rm '%s'" % (rarname))
os.system("mv *.kepub.epub ./kepub/")
os.system("mv *.epub ./epub/")
print("å®Œæˆï¼Œæ”¶å·¥ï¼Œæ’’èŠ±ï¼ï¼ğŸ‰ğŸ‰")
